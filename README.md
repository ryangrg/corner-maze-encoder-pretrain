# Corner Maze Encoder Pretrain

This repository explores how to compress visual observations collected from a rodent-scale corner maze into a compact latent space that can condition downstream reinforcement learning (RL) agents. The raw observations are stereo renderings (left- and right-eye) of the 2s2c behavioral task inside a Fusion360 model of the maze. Each pose in an 11Ã—11 spatial grid produces four views aligned with the cardinal directions, except at corners where diagonal headings (NE, NW, SE, SW) are captured. All renders are flattened into single-channel (B/W) images and paired so that a single tensor contains both eyes.

## Project Goals
- Build preprocessing utilities that organize the stereo renders, flatten them, and stack them into tensors suitable for PyTorch.
- Prototype multiple encoder architectures (CNNs and alternative tensor representations) to learn latent features that uniquely identify maze poses.
- Evaluate the learned encoders by decoding pose identity and by feeding the latent vectors into lightweight RL agents in a MiniGrid-style simulator of the 2s2c task.

## Workflow
1) Start with a base set of image from blairlab-fusion-capture, from this base set of images all pose views can be generated by rotating Cartesian positions and directional values.
2) Create a pytorch friendly dataset that is saved as a .pt file. The script that does this will turn images to a single layer gray scale and then combine left and right eye views from a single pose and horizontally mirror the right eye. Each new tensor takes the pose name and drops the l and r from the file name and uses that as a label for the tensor for that pose along with creating an ID value. See create_dataset.py for more details.
3) Find duplicate images allowing for render noise to be passed, see find_duplicate_pairs.py for details on this process. After working through several passes of the script using different allowances of variance followed by visual inspection using the visualize_image_stack.py it was found that 

## Image Clustering Method
Clustering similar views from a pose, by first checking for duplicates allowing for a variance between pixel values.
This method was a first crude pass where too much variance clusters images together that shouldn't be and too
tight of a tolerance leaves out images from clusters. Taking an approach to run a loose variance that clusters
compositionaly similar images but then has a hard time determining if a barrier is in the image or other subtleties.
A view through a barrier renders a monitor slightly more blurry than otherwise. Other subtleties can include odd reflexes
from side wall when there is cue and bright dull spots from barrier reflections.
